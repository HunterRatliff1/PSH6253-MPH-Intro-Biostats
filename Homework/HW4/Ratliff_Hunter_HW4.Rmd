---
title: 'Homework #4'
author: "Hunter Ratliff"
date: "11/20/2019"
output:
  pdf_document: 
    number_sections: yes
    toc: yes
    toc_depth: 2
  word_document: 
    highlight: tango
    toc: yes
    toc_depth: 2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=T, warning=F, message=F, collapse = T)
library(pander)
library(tidyverse)
library(ggthemes)
library(scales)
library(gridExtra)
options(tinytex.verbose = TRUE)

### LATEX HELP ###
# \definecolor{bgblue}{RGB}{217, 237, 247}
# \textcolor{red}{easily} \colorbox{bgblue}{this text}
# \colorbox{bgblue}{asd}
# \noindent
# {\color{bgblue} \rule{\linewidth}{1mm} }

# see http://joshua.smcvt.edu/latex2e/_005cfbox-_0026-_005cframebox.html
```

# Question 1

> 1. `r kableExtra::text_spec("Propranolol is a standard drug given to ease the pain of patients with episodes of unstable angina. A new drug for the treatment of this disease is tested on 30 pairs of patients who are matched on a one-to-one basis according to age, sex, and clinical condition and are assessed as to the severity of their pain. Suppose that in 15 pairs of patients, the patient with the new drug has less pain; in 10 pairs of patients, the patient with propranolol has less pain; and in 5 pairs of patients, the pain is about the same with the two drugs. ", color = "gray")`

In this question, we found that compared to , the **new drug** decreased pain better in **15** pairs, **propranolol** decreased pain better in **10** pairs, and 5 pairs were about the same. 

## Appropriate test

> 1a. `r kableExtra::text_spec("What is the appropriate test to use here?", color = "purple")`

The **sign test** is most appropriate in this situation, given that the data is paired and we can distinguish order, but _cannot measure distance_

## Perform test & report p-value

> 1b. `r kableExtra::text_spec("Perform the test and report a p-value", color = "purple")`

We'll ignore the pairs that were tied, giving us n=25. We'll define success as the new drug being superior to propranolol in terms of pain relief, giving us x=15

$$H_0: P(NewDrug > propranolol) = P(NewDrug < propranolol)$$

```{r}
binom.test(15, n=25)
```

At a p-value of p=`r round(binom.test(15, n=25)$p.value,3)`, we do not reject the null hypothesis^[I know the instructions say that we need to report which hypothesis we are testing. If I don't explicity include it in the write up, check the R output as it may be listed there].

# Question 2

> 2. `r kableExtra::text_spec("Polyunsaturated fatty acids in the diet favorably affect several risk factors for cardiovascular disease. The principal dietary polyunsaturated fat is linoleic acid. To test the effects of dietary supplementation with linoleic acid on blood pressure, 17 adults consumed 23 g/day of safflower oil, high in linoleic acid, for 4 weeks. Systolic blood pressure (SBP) measurements were taken at baseline (before ingestion of oil) and 1 month later, with the mean values over several readings at each visit given in Table 9.12.", color = "gray")`

Hypertension (Rosnerâ€™s book 9.17-9.21)

```{r}
HTN <- readr::read_csv("Hypertension.csv")
HTN[c(1:3),] # first 3 rows
```


## What **parametric** test could be used?

> 2a. `r kableExtra::text_spec("What parametric test could be used to test for the effect of linoleic acid on SBP?", color = "purple")`

The parametric test used to evaluate the difference between these paired groups would either be a **paired t-test** or a **one-sample t-test** of the differences

## Results of test

> 2b. `r kableExtra::text_spec("Perform the test in Problem 2a", color = "purple")`

```{r}
t.test(HTN$Baseline_SBP, HTN$`1_mo_SBP`, paired=T)
```

```{r, echo=F}
t.test(HTN$Baseline_SBP, HTN$`1_mo_SBP`, paired=T) %>% pander()
```



## What **non-parametric** test could be used?

> 2c. `r kableExtra::text_spec("What non parametric test could be used to test for the effect of linoleic acid on SBP", color = "purple")`

The _non-parametric_ alternative to the one-sample t-test is the **Wilcoxon Signed-Rank test**

## Results of test

> 2d. `r kableExtra::text_spec("Perform the test in Problem 2c", color = "purple")`

```{r, warning=T, collapse=F}
wilcox.test(HTN$Diff)
```

```{r, echo=F}
wilcox.test(HTN$Diff) %>% pander()
```

**Note:** The `wilcox.test()` above does not ignore observations with a diff=0, so exact p-values can't be calculated. R uses the normal approximation, which should be okay since we have 16 observations with non-missing differences



## Compare results

> 2e. `r kableExtra::text_spec("Compare your results in Problems 2b and 2d, and discuss which method you feel is more appropriate", color = "purple")`

The results between both tests are similar, so it really comes down to if the distribution is normal. Our n=17, so we can't fall back on the CLT, so we'll run some tests and plots:

```{r}
shapiro.test(HTN$Diff) %>% pander()
```



```{r, echo=F, fig.height=3}
p1 <- HTN %>% ggplot() + 
  geom_qq(aes(sample=Diff)) +
  geom_qq_line(aes(sample=Diff)) +
  # coord_equal() +
  labs(title="QQplot of HTN$Diff")

p2 <- HTN %>% ggplot(aes(x=Diff)) +
  geom_histogram(bins=8, colour="black", 
                          aes(y=..density.., fill=..count..)) +
  scale_fill_gradient("Count", low="#DCDCDC", high="#7C7C7C") +
  stat_function(fun=dnorm,
                color="red",
                args=list(mean=mean(HTN$Diff), 
                          sd=sd(HTN$Diff))) +
  guides(fill=F) +
  labs(title="Histogram of HTN$Diff", subtitle = "With superimposed normal distribution")
grid.arrange(p1, p2, ncol=2)
rm(p1, p2)
```

The histogram doesn't look very good, but the QQ-plot doesn't look *that* bad^[In fact, when I ran simulations of the qqplot using `rnorm(17, mean = mean(HTN$Diff), sd=sd(HTN$Diff)`, this QQ-plot looks pretty typical] and the Shapiro-Wilk normality test indicated that this distribution is likely normal. 

So with all that said, I think it's safe enough to assume this is normally distributed, and I'd therefore go with the **paired t-test**. 


# Question 3

> 3. `r kableExtra::text_spec("The drug erythromycin has been proposed to possibly lower the risk of premature delivery.  A related area of interest is its association with the incidence of side effects during pregnancy.  Assume 30% of all pregnant women complain of nausea between weeks 24 and 28 of pregnancy.  Furthermore, suppose that of 200 women who are taking erythromycin regularly during the period, 110 complain of nausea. ", color = "gray")`

$$p = 0.30 $$
$$\hat{p} = 110 / 200 = 0.55$$


> 3a. `r kableExtra::text_spec("Test the hypothesis that in incidence rate of nausea for the erythromycin group is the same for a typical pregnant woman and construct a 95% CI as appropriate.", color = "purple")`

$$H_0: p = \hat{p}$$

To construct the 95% CI, $n\hat{p}(1-\hat{p})\ge5$, which is the case here `(npq=42)` so we can use the normal approximation

We find the SE with this equation, and then can find the 95% CI:

$$se = \sqrt\frac{\hat{p}(1-\hat{p})}{n} = \sqrt\frac{.55\times.45}{200}=.0352$$
$$\hat{p}\pm1.96\times se\ \ =\ \ .55\pm 1.96\times .0352$$
This gives us a 95% CI of **[`0.481` - `0.619`]**

```{r}
se <- sqrt(.55*.45/200)

# Lower CI
round(.55 - 1.96 * se, 3)

# Upper CI
round(.55 + 1.96 * se, 3)
```

We find our Z score & p-value with the equation below:

$$Z = \frac{\hat{p}-p_0}{\sqrt\frac{p_0(1-p_0)}{n}} = \frac{.55-.3}{\sqrt\frac{.3(.7)}{200}}$$

```{r, collapse=F}
Z <- (.55-.3) /  (sqrt(.3*.7/200))
2*pnorm(-abs(Z))
```

This p-value is well below 0.05, allowing us to reject $H_0$.

# Question 4

> 4. `r kableExtra::text_spec("Using the Hospital.DAT, from table 2.13 (page 36)", color = "gray")`

```{r}
Hosp <- readr::read_csv("Hospital.csv") %>%
  mutate(
    Antibio  = factor(recode(Antibio, "1"="Yes", "2"="No")),
    Bact_cul = factor(recode(Bact_cul, "1"="Yes", "2"="No"))
  )
```


## Which significance test to use

> 4a. `r kableExtra::text_spec("What significance test can be used to assess whether there is a relationship between receiving an antibiotic and receiving a bacterial culture while in the hospital? (question 10.6)", color = "purple")`

Considering that this is categorical data, the Chi-squared test would be ideal. However, looking at the contingency table below, I expect at least 20% of cells have an expected value less than five^[Indeed, 50% of cells have an expected value less than 5]. Because this is the case, we'll use `fisher.test()`^[It could also be argued that we should be using McNemar's test (since you shouldn't be getting antibiotics without a blood culture), but it still gives a p-value of p=1 anyways].

```{r}
chisq.test(Hosp$Antibio, Hosp$Bact_cul)$observed
```



## What's the p-value?

> 4b. `r kableExtra::text_spec("Perform the test in Problem 4a and report a p-value (question 10.7)", color = "purple")`

```{r}
fisher.test(Hosp$Antibio, Hosp$Bact_cul)
```

This gives us a `p-value = 1`

```{r, echo=F}
fisher.test(Hosp$Antibio, Hosp$Bact_cul) %>% pander()
```

# Question 5

> 5. `r kableExtra::text_spec("Two drugs (A,B) are compared for the medical treatment of duodenal ulcer.  For this purpose, patients are carefully matched with regard to age, gender, and clinical condition.  The treatment results based on 200 matched pairs show that for 89 matched pairs both treatments are effective; for 90 matched pairs both treatments are ineffective; for 5 matched pairs drug A is effective, whereas drug B is ineffective; and for 16 matched pairs drug B is effective, whereas drug A in ineffective.", color = "gray")`

```{r}
Drugs <- matrix(c(89, 16, 5, 90), 
                nrow=2, ncol=2,
                dimnames = list(DrugA=c("Works", "Not"),
                                DrugB=c("Works", "Not")))
# contingency table
Drugs
```



## What test to use

> 5a. `r kableExtra::text_spec("What test procedure can be used to assess the results?  (question 10.8)", color = "purple")`

To compare these two drugs we can use th **McNemar test**. Because we have 21 discordant pairs ($n_D \hat{p_A} \hat{q_A} \ge 20$) we can use the normal approximation.


## Perform test & report p-value

> 5b. `r kableExtra::text_spec("Perform the test above and report a p-value.  (question 10.9)", color = "purple")`

```{r}
mcnemar.test(Drugs)
```

This gives us a p-value of p=`r round(mcnemar.test(Drugs)$p.value,3)` (`r round(mcnemar.test(Drugs,correct = F)$p.value,3)` without the continuity correction).


# Question 6

> 6. `r kableExtra::text_spec("T6.	Suppose a cross-sectional survey examines the association between the smoking and drinking behavior among a random sample of 100 participants. The following table give the frequency counts for the number of participants with smoking (never, former, current) and drinking (never, former, current).", color = "gray")`

```{r}
Smoke_Drink <- matrix(c(15, 20, 5, 5, 15, 10, 10, 5, 15), 
                      nrow = 3, ncol=3,
                      dimnames = list(Drink=c("Never Drink", "Former Drink", "Current Drink"),          
                                      Smoke=c("Never Smoke", "Former Smoke", "Current Smoke")))
pander(Smoke_Drink)
```

> 6a. `r kableExtra::text_spec("Is drinking status independent of smoking status? Perform the test, report the p-value and interpret the results.", color = "purple")`

$H_0:$ Drinking status independent of smoking status

```{r}
# Chi-Square Test of Independence
chisq.test(Smoke_Drink) %>% pander()

# graphics::mosaicplot(Smoke_Drink, shade=T, color=T)
```

With a p-value of p = `r round(chisq.test(Smoke_Drink)$p.value,4)` we can conclude that drinking status is **not** independent of smoking status.

***

See Github for full source code: https://github.com/HunterRatliff1/PSH6253-MPH-Intro-Biostats